{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AML - Streamlining Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Understand the architecture and terms introduced by Azure Machine Learning (AML)\n",
    "\n",
    "Install the Python SDK: make sure to install notebook, and contrib\n",
    "\n",
    "```\n",
    "conda create -n azureml -y Python=3.6\n",
    "source activate azureml\n",
    "pip install --upgrade azureml-sdk[notebooks,contrib] \n",
    "conda install ipywidgets\n",
    "jupyter nbextension install --py --user azureml.widgets\n",
    "jupyter nbextension enable azureml.widgets --user --py\n",
    "```\n",
    "\n",
    "You will need to restart jupyter after this Detailed instructions are [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python/?WT.mc_id=bert-notebook-abornst)\n",
    "\n",
    "If you need a free trial account to get started you can get one [here](https://azure.microsoft.com/en-us/offers/ms-azr-0044p/?WT.mc_id=bert-notebook-abornst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "* A name for your workspace\n",
    "* Your subscription id\n",
    "* The resource group name\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace/?WT.mc_id=bert-notebook-abornst) object from the existing workspace you created in the Prerequisites step or create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "# subscription_id = ''\n",
    "# resource_group  = ''\n",
    "# workspace_name  = ''\n",
    "#     ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "#     ws.write_config()\n",
    "\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "    print('Library configuration succeeded')\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute\n",
    "\n",
    "### Create a GPU remote compute target\n",
    "We need to create a GPU [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to perform the fine-tuning. In this example, we create an AmlCompute cluster as our training compute resource. Please find the information of Azure VM size in below table.\n",
    "\n",
    "|       VM Size      | CPU |    GPU   | Storage (SSD) | GPU memory | InfiniBand |\n",
    "|:------------------:|:---:|:--------:|:-------------:|:----------:|:----------:|\n",
    "|    Standard_NC6    |  6  |  1 x K80 |    340 GiB    |    8 GiB   |     No     |\n",
    "|    Standard_NC12   |  12 |  2 x K80 |    680 GiB    |   16 GiB   |     No     |\n",
    "|    Standard_NC24   |  24 |  4 x K80 |    1440 GiB   |   32 GiB   |     No     |\n",
    "|   Standard_NC24r   |  24 |  4 x K80 |    1440 GiB   |   32 GiB   |     Yes    |\n",
    "|  Standard_NC6s_v3  |  6  | 1 x V100 |    736 GiB    |   16 GiB   |     No     |\n",
    "|  Standard_NC12s_v3 |  12 | 2 x V100 |    1474 GiB   |   32 GiB   |     No     |\n",
    "|  Standard_NC24s_v3 |  24 | 4 x V100 |    2948 GiB   |   64 GiB   |     No     |\n",
    "| Standard_NC24rs_v3 |  24 | 4 x V100 |    2948 GiB   |   64 GiB   |     Yes    |\n",
    "\n",
    "***Note that*** you need to request NCv3-serie quota if you would like to use NVIDIA Tesla V100\n",
    "This code creates a cluster for you if it does not already exist in your workspace.\n",
    "\n",
    "__One Time Creation__\n",
    "\n",
    "\n",
    "Choose a name for your GPU cluster cluster_name = \"gpucluster\" # Verify that cluster does not exist already try: gpu_cluster = ComputeTarget(workspace = ws, name = cluster_name) except ComputeTargetException: compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=0, max_nodes=1) gpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config) gpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cluster_name = \"cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6',\n",
    "                                                           min_nodes=1,\n",
    "                                                           max_nodes=4)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "blob_datastore = Datastore.register_azure_file_share(workspace=ws, \n",
    "                                                     datastore_name='<<SECRET>>', \n",
    "                                                     file_share_name=\"<<SECRET>>\", \n",
    "                                                     account_name=\"<<SECRET>>\",\n",
    "                                                     account_key='<<SECRET>>')\n",
    "\n",
    "\n",
    "\n",
    "#get named datastore from current workspace\n",
    "datastore = Datastore.get(ws, datastore_name='project_zero')\n",
    "print(blob_datastore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALM Training Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core.runconfig import RunConfiguration, DataReferenceConfiguration\n",
    "proj_root = \"project_zero/ds1\"\n",
    "\n",
    "\n",
    "dr = DataReferenceConfiguration(datastore_name=datastore.name, \n",
    "                                path_on_datastore=proj_root,\n",
    "#                                path_on_compute='/datastore', path_on_compute doesn't work with mount\n",
    "                                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_registry = ContainerRegistry()\n",
    "container_registry.address = '>>> SECRET <<<'\n",
    "container_registry.username = '>>> SECRET <<<'\n",
    "container_registry.password = '>>> SECRET <<<'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.docker.enabled = True\n",
    "#run_config.environment.docker.base_image='computervisi6b3936b2.azurecr.io/dtron2:3'\n",
    "run_config.environment.docker.base_image='yolact:1'\n",
    "run_config.environment.docker.base_image_registry=container_registry\n",
    "\n",
    "\n",
    "run_config.data_references = {datastore.name: dr}\n",
    "\n",
    "# GPU support: Azure automatically detects and uses the NVIDIA Docker extension when it is available.\n",
    "run_config.environment.python.user_managed_dependencies=True  # use your own installed packages instead of an AML created Conda env\n",
    "\n",
    "run_config.target = compute_target # specify the compute target; obscure error message: `docker image` cannot run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Machine Learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'zerowaste'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mount = datastore.path(proj_root).as_mount()\n",
    "img_path = os.path.join(str(base_mount), 'parsed')\n",
    "masks_path = os.path.join(str(base_mount), 'experiments/dataset_config')                                                                                                   \n",
    "output_path = os.path.join(str(base_mount),LOGS_AND_MODEL_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_mount = datastore.path(proj_root).as_mount()\n",
    "img_path = os.path.join(str(base_mount), 'parsed')\n",
    "masks_path = os.path.join(str(base_mount), 'experiments/dataset_config')\n",
    "\n",
    "                                                                                                    ### update me\n",
    "output_path = os.path.join(str(base_mount),LOGS_AND_MODEL_PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': base_mount,\n",
    "    '--img-folder': img_path,\n",
    "    '--masks-folder': masks_path,\n",
    "    '--output-folder': output_path,\n",
    "    #'--config-file': 'configs/R_50_1x.yaml'\n",
    "    '--config-file': 'yolact_plus_resnet50_zw1_3c_mnt_x1_config', #'yolact_resnet50_zwds1_3label_config',\n",
    "\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=\"../../../yolact_alm/\",\n",
    "                    script_params=script_params,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script=\"yolact_alm_runner.py\",\n",
    "                    use_docker=True,\n",
    "                    #use_gpu=True,\n",
    "                    image_registry_details=container_registry,\n",
    "                    user_managed=True,\n",
    "                    custom_docker_image='yolact:1', #notice this is short name, different from ScriptRun\n",
    "                    inputs=[base_mount]) #tell the system to mount, or if the script params contain ds.mount(), it will mount without this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(est)\n",
    "print(f\"Run Details: {run.get_details()['runId']}\")\n",
    "\n",
    "print(f'Run Status: {run.get_status()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Run\n",
    "\n",
    "Below please find the elapsed time per epoch using deferent Azure GPU VMs with above hyperparameters\n",
    "\n",
    "|     GPU counts |    1 GPU    |       2 GPU |      4 GPU |\n",
    "|---------------:|:-----------:|------------:|-----------:|\n",
    "|      NC-series | 191 s/epoch | 105 s/epoch | 60 s/epoch |\n",
    "|    NCv3-series |  36 s/epoch |  22 s/epoch | 13 s/epoch |\n",
    "| NCv3 with fp16 |  32 s/epoch |  18 s/epoch | 12 s/epoch |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning with Hyperparameter Tuning\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources\n",
    "- https://nbviewer.jupyter.org/github/microsoft/AzureML-BERT/blob/master/finetune/PyTorch/notebooks/Pretrained-BERT-GLUE.ipynb\n",
    "- https://nbviewer.jupyter.org/github/microsoft/AzureML-BERT/blob/master/finetune/PyTorch/notebooks/Pretrained-BERT-NER.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
