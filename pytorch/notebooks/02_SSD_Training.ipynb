{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "1.5.0\n",
      "0.6.0a0+82fd1c8\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# version\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "from models.base_cfg import ssd300_cfg as cfg\n",
    "from models.base_cfg import ML_WEIGHTS_PATH, DS01_CLASSES\n",
    "from utils import ssd\n",
    "\n",
    "import cv2\n",
    "from utils import data_processor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_classes': 6,\n",
       " 'input_size': 300,\n",
       " 'base': 300,\n",
       " 'base_model': 'vgg16_reducedfc.pth',\n",
       " 'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n",
       " 'feature_maps': [38, 19, 10, 5, 3, 1],\n",
       " 'steps': [8, 16, 32, 64, 100, 300],\n",
       " 'min_sizes': [30, 60, 111, 162, 213, 264],\n",
       " 'max_sizes': [60, 111, 162, 213, 264, 315],\n",
       " 'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
       " 'cuda': True,\n",
       " 'train_labeled_file': '/home/redne/mnt/project_zero/project_zero/ds1/experiments/data/train_labels_dev.npy',\n",
       " 'val_labeled_file': '/home/redne/mnt/project_zero/project_zero/ds1/experiments/data/val_labels_dev.npy',\n",
       " 'img_dir': '/home/redne/mnt/project_zero/project_zero/ds1/parsed/',\n",
       " 'logs': 'checkpoints/logs.txt',\n",
       " 'color_mean': (104, 117, 123),\n",
       " 'variance': ([0.1, 0.2],)}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if cfg['cuda']:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    if not cfg['cuda']:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "    \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(f'device : {device}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the SSD architecture and the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f746c267550>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7f746cb27090>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#root = '/home/redne/mnt/project_zero/project_zero/ds1/parsed/'\n",
    "#train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "imgpath, annopath = data_processor.make_datapath_list(cfg['img_dir'])\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = imgpath[:-100], annopath[:-100], imgpath[-100:], annopath[-100:]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\"\"\"\n",
    "\n",
    "# Dataset\n",
    "voc_classes =  DS01_CLASSES\n",
    "\n",
    "train_dataset = data_processor.VOCDataset(train_img_list, train_anno_list, phase=\"train\", \n",
    "                                          transform=data_processor.VOC_DataTransform(\n",
    "                                              cfg['input_size'], cfg['color_mean']), \n",
    "                                          transform_anno=data_processor.Anno_json(voc_classes))\n",
    "\n",
    "val_dataset = data_processor.VOCDataset(val_img_list, val_anno_list, phase=\"val\",\n",
    "                                    transform=data_processor.VOC_DataTransform(\n",
    "    cfg['input_size'], cfg['color_mean']), transform_anno=data_processor.Anno_json(voc_classes))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "#batch_size = 8\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_processor.od_collate_fn)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_processor.od_collate_fn)\n",
    "\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
    "dataloaders_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Trainign SSD\n",
    "\n",
    "- First download the fc-reduced VGG-16 PyTorch base network weights at: https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\n",
    "- By default, we assume you have downloaded the file in the ssd.pytorch/weights dir:\n",
    "\n",
    "\n",
    "```\n",
    "cd ~/mnt/project_zero/pytorch/weights/\n",
    "wget https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth\n",
    "#adjust the keys in the weights file to fit for current model\n",
    "python3 vggweights.py\n",
    "cd ..\n",
    "```\n",
    "\n",
    "https://github.com/yczhang1017/SSD_resnet_pytorch#training-ssd\n",
    "\n",
    "\n",
    "- Download the PyTorch pre-trained SSD300 model on VOC from [here](https://s3.amazonaws.com/amdegroot-models/ssd300_mAP_77.43_v2.pth):\n",
    "    \n",
    "_https://s3.amazonaws.com/amdegroot-models/ssd300_mAP_77.43_v2.pth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_classes': 6,\n",
       " 'input_size': 300,\n",
       " 'base': 300,\n",
       " 'base_model': 'vgg16_reducedfc.pth',\n",
       " 'bbox_aspect_num': [4, 6, 6, 6, 4, 4],\n",
       " 'feature_maps': [38, 19, 10, 5, 3, 1],\n",
       " 'steps': [8, 16, 32, 64, 100, 300],\n",
       " 'min_sizes': [30, 60, 111, 162, 213, 264],\n",
       " 'max_sizes': [60, 111, 162, 213, 264, 315],\n",
       " 'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
       " 'cuda': True,\n",
       " 'train_labeled_file': '/home/redne/mnt/project_zero/project_zero/ds1/experiments/data/train_labels_dev.npy',\n",
       " 'val_labeled_file': '/home/redne/mnt/project_zero/project_zero/ds1/experiments/data/val_labels_dev.npy',\n",
       " 'img_dir': '/home/redne/mnt/project_zero/project_zero/ds1/parsed/',\n",
       " 'logs': 'checkpoints/logs.txt',\n",
       " 'color_mean': (104, 117, 123),\n",
       " 'variance': ([0.1, 0.2],)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 264M\n",
      "-rwxrwxrwx 1 root root 93M May 31 20:27 dev2_ssd300_10_053120.pth\n",
      "-rwxrwxrwx 1 root root 93M May 31 19:41 dev_ssd300_10_053120.pth\n",
      "-rwxrwxrwx 1 root root 79M May 31 12:37 vgg16_reducedfc.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -lh '/home/redne/mnt/project_zero/pytorch/weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/redne/mnt/project_zero/pytorch/weights/vgg16_reducedfc.pth'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(ML_WEIGHTS_PATH, cfg['base_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ssd.build_ssd(phase=\"train\",num_classes=cfg['num_classes'])\n",
    "vgg_weights = torch.load(os.path.join(ML_WEIGHTS_PATH, cfg['base_model']))\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:  \n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "if cfg['cuda']:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### NEXT DO FocalLoss as the loss metric (5/31/20)\n",
    "https://github.com/kentaroy47/SSD.objectdetection.pytorch/blob/master/dev/train_ssd%2Bfocal_loss.ipynb\n",
    "\n",
    "from utils.focalloss import FocalLoss\n",
    "from utils.ssd_model import match\n",
    "\n",
    "# define loss\n",
    "criterion = FocalLoss(num_classes=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd import MultiBoxLoss\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3,\n",
    "                      momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Training on：\", device)\n",
    "\n",
    "\n",
    "    net.to(device)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(num_epochs+1):\n",
    "\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train() \n",
    "                print('（train）')\n",
    "            else:\n",
    "                if((epoch+1) % 10 == 0):\n",
    "                    net.eval()\n",
    "                    print('-------------')\n",
    "                    print('（val）')\n",
    "                else:\n",
    "                    \n",
    "                    continue\n",
    "\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device) for ann in targets]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "\n",
    "                        \n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 10 == 0):  \n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('>> training iter {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                        \n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"../outputs/log_output_dev3_060120.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "\n",
    "        \n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), ML_WEIGHTS_PATH + 'dev3_ssd300_' +\n",
    "                       str(epoch+1) + '_060120.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on： cuda:0\n",
      "-------------\n",
      "Epoch 1/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 10 || Loss: 11.1827 || 10iter: 98.8239 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:168.3871 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.3869 sec.\n",
      "-------------\n",
      "Epoch 2/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 20 || Loss: 11.2703 || 10iter: 68.8174 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:146.4156 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.8278 sec.\n",
      "-------------\n",
      "Epoch 3/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 30 || Loss: 9.7713 || 10iter: 37.5422 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:128.4520 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  123.8475 sec.\n",
      "-------------\n",
      "Epoch 4/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 40 || Loss: 9.3273 || 10iter: 9.5673 sec.\n",
      ">> training iter 50 || Loss: 9.0907 || 10iter: 99.4272 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:116.9756 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  128.2546 sec.\n",
      "-------------\n",
      "Epoch 5/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 60 || Loss: 9.2781 || 10iter: 77.5786 sec.\n",
      "-------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:120.3393 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  126.4728 sec.\n",
      "-------------\n",
      "Epoch 6/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 70 || Loss: 9.4010 || 10iter: 46.8415 sec.\n",
      "-------------\n",
      "epoch 6 || Epoch_TRAIN_Loss:114.5447 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  123.3327 sec.\n",
      "-------------\n",
      "Epoch 7/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 80 || Loss: 7.1010 || 10iter: 18.0579 sec.\n",
      ">> training iter 90 || Loss: 6.7268 || 10iter: 99.8424 sec.\n",
      "-------------\n",
      "epoch 7 || Epoch_TRAIN_Loss:91.9943 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.2919 sec.\n",
      "-------------\n",
      "Epoch 8/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 100 || Loss: 6.7163 || 10iter: 92.3622 sec.\n",
      "-------------\n",
      "epoch 8 || Epoch_TRAIN_Loss:85.6665 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  128.7044 sec.\n",
      "-------------\n",
      "Epoch 9/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 110 || Loss: 6.3201 || 10iter: 61.6928 sec.\n",
      "-------------\n",
      "epoch 9 || Epoch_TRAIN_Loss:81.1043 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  126.7745 sec.\n",
      "-------------\n",
      "Epoch 10/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 120 || Loss: 6.0871 || 10iter: 31.0196 sec.\n",
      ">> training iter 130 || Loss: 6.3329 || 10iter: 95.6834 sec.\n",
      "-------------\n",
      "（val）\n",
      "-------------\n",
      "epoch 10 || Epoch_TRAIN_Loss:80.0026 ||Epoch_VAL_Loss:23.8301\n",
      "timer:  145.8023 sec.\n",
      "-------------\n",
      "Epoch 11/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 140 || Loss: 5.9119 || 10iter: 102.0670 sec.\n",
      "-------------\n",
      "epoch 11 || Epoch_TRAIN_Loss:77.9626 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  128.4655 sec.\n",
      "-------------\n",
      "Epoch 12/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 150 || Loss: 6.0827 || 10iter: 67.9896 sec.\n",
      "-------------\n",
      "epoch 12 || Epoch_TRAIN_Loss:77.1148 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  124.2016 sec.\n",
      "-------------\n",
      "Epoch 13/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 160 || Loss: 5.8543 || 10iter: 37.0956 sec.\n",
      "-------------\n",
      "epoch 13 || Epoch_TRAIN_Loss:74.8808 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.0676 sec.\n",
      "-------------\n",
      "Epoch 14/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 170 || Loss: 5.2836 || 10iter: 6.7240 sec.\n",
      ">> training iter 180 || Loss: 5.8060 || 10iter: 97.5672 sec.\n",
      "-------------\n",
      "epoch 14 || Epoch_TRAIN_Loss:72.9331 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.2017 sec.\n",
      "-------------\n",
      "Epoch 15/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 190 || Loss: 5.7725 || 10iter: 75.3894 sec.\n",
      "-------------\n",
      "epoch 15 || Epoch_TRAIN_Loss:71.0619 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.9257 sec.\n",
      "-------------\n",
      "Epoch 16/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 200 || Loss: 5.1715 || 10iter: 48.2900 sec.\n",
      "-------------\n",
      "epoch 16 || Epoch_TRAIN_Loss:70.9174 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.8802 sec.\n",
      "-------------\n",
      "Epoch 17/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 210 || Loss: 5.2526 || 10iter: 17.8802 sec.\n",
      ">> training iter 220 || Loss: 4.8900 || 10iter: 92.0090 sec.\n",
      "-------------\n",
      "epoch 17 || Epoch_TRAIN_Loss:67.8310 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  117.7822 sec.\n",
      "-------------\n",
      "Epoch 18/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 230 || Loss: 5.0286 || 10iter: 87.3987 sec.\n",
      "-------------\n",
      "epoch 18 || Epoch_TRAIN_Loss:66.7835 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.9316 sec.\n",
      "-------------\n",
      "Epoch 19/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 240 || Loss: 5.1131 || 10iter: 55.7077 sec.\n",
      "-------------\n",
      "epoch 19 || Epoch_TRAIN_Loss:67.1792 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.3634 sec.\n",
      "-------------\n",
      "Epoch 20/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 250 || Loss: 5.3512 || 10iter: 28.9702 sec.\n",
      ">> training iter 260 || Loss: 5.1049 || 10iter: 95.7426 sec.\n",
      "-------------\n",
      "（val）\n",
      "-------------\n",
      "epoch 20 || Epoch_TRAIN_Loss:67.8565 ||Epoch_VAL_Loss:21.7323\n",
      "timer:  142.6116 sec.\n",
      "-------------\n",
      "Epoch 21/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 270 || Loss: 5.1985 || 10iter: 98.9747 sec.\n",
      "-------------\n",
      "epoch 21 || Epoch_TRAIN_Loss:65.2978 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  124.9236 sec.\n",
      "-------------\n",
      "Epoch 22/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 280 || Loss: 5.0540 || 10iter: 70.4159 sec.\n",
      "-------------\n",
      "epoch 22 || Epoch_TRAIN_Loss:66.4440 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  128.2498 sec.\n",
      "-------------\n",
      "Epoch 23/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 290 || Loss: 4.8261 || 10iter: 37.5808 sec.\n",
      "-------------\n",
      "epoch 23 || Epoch_TRAIN_Loss:61.7124 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  120.7059 sec.\n",
      "-------------\n",
      "Epoch 24/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 300 || Loss: 5.0164 || 10iter: 7.8964 sec.\n",
      ">> training iter 310 || Loss: 4.1490 || 10iter: 96.9149 sec.\n",
      "-------------\n",
      "epoch 24 || Epoch_TRAIN_Loss:61.6068 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.4753 sec.\n",
      "-------------\n",
      "Epoch 25/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 320 || Loss: 4.8004 || 10iter: 74.6985 sec.\n",
      "-------------\n",
      "epoch 25 || Epoch_TRAIN_Loss:60.1826 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.9518 sec.\n",
      "-------------\n",
      "Epoch 26/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 330 || Loss: 5.1473 || 10iter: 48.2887 sec.\n",
      "-------------\n",
      "epoch 26 || Epoch_TRAIN_Loss:61.7334 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  127.0588 sec.\n",
      "-------------\n",
      "Epoch 27/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 340 || Loss: 4.3078 || 10iter: 17.9803 sec.\n",
      ">> training iter 350 || Loss: 4.5716 || 10iter: 95.8551 sec.\n",
      "-------------\n",
      "epoch 27 || Epoch_TRAIN_Loss:58.1057 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  122.1587 sec.\n",
      "-------------\n",
      "Epoch 28/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 360 || Loss: 4.6005 || 10iter: 85.0773 sec.\n",
      "-------------\n",
      "epoch 28 || Epoch_TRAIN_Loss:59.7190 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.3341 sec.\n",
      "-------------\n",
      "Epoch 29/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 370 || Loss: 4.8327 || 10iter: 59.5797 sec.\n",
      "-------------\n",
      "epoch 29 || Epoch_TRAIN_Loss:56.9876 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  124.6625 sec.\n",
      "-------------\n",
      "Epoch 30/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 380 || Loss: 4.6585 || 10iter: 29.1745 sec.\n",
      ">> training iter 390 || Loss: 4.2921 || 10iter: 89.5011 sec.\n",
      "-------------\n",
      "（val）\n",
      "-------------\n",
      "epoch 30 || Epoch_TRAIN_Loss:55.7676 ||Epoch_VAL_Loss:18.9962\n",
      "timer:  134.7126 sec.\n",
      "-------------\n",
      "Epoch 31/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 400 || Loss: 4.4484 || 10iter: 95.8905 sec.\n",
      "-------------\n",
      "epoch 31 || Epoch_TRAIN_Loss:54.7920 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.6933 sec.\n",
      "-------------\n",
      "Epoch 32/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 410 || Loss: 4.0374 || 10iter: 66.3859 sec.\n",
      "-------------\n",
      "epoch 32 || Epoch_TRAIN_Loss:53.6432 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  122.9478 sec.\n",
      "-------------\n",
      "Epoch 33/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 420 || Loss: 4.1384 || 10iter: 39.4203 sec.\n",
      "-------------\n",
      "epoch 33 || Epoch_TRAIN_Loss:54.3600 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  124.2838 sec.\n",
      "-------------\n",
      "Epoch 34/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 430 || Loss: 4.6944 || 10iter: 8.5120 sec.\n",
      ">> training iter 440 || Loss: 3.8047 || 10iter: 94.2264 sec.\n",
      "-------------\n",
      "epoch 34 || Epoch_TRAIN_Loss:53.1167 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  120.4884 sec.\n",
      "-------------\n",
      "Epoch 35/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 450 || Loss: 3.5445 || 10iter: 75.8546 sec.\n",
      "-------------\n",
      "epoch 35 || Epoch_TRAIN_Loss:52.3461 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.6228 sec.\n",
      "-------------\n",
      "Epoch 36/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 460 || Loss: 3.7164 || 10iter: 45.0323 sec.\n",
      "-------------\n",
      "epoch 36 || Epoch_TRAIN_Loss:51.7368 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  118.3440 sec.\n",
      "-------------\n",
      "Epoch 37/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 470 || Loss: 3.6307 || 10iter: 17.5984 sec.\n",
      ">> training iter 480 || Loss: 3.6710 || 10iter: 94.0637 sec.\n",
      "-------------\n",
      "epoch 37 || Epoch_TRAIN_Loss:49.7341 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.0740 sec.\n",
      "-------------\n",
      "Epoch 38/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 490 || Loss: 3.7654 || 10iter: 84.5102 sec.\n",
      "-------------\n",
      "epoch 38 || Epoch_TRAIN_Loss:52.0414 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.0948 sec.\n",
      "-------------\n",
      "Epoch 39/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 500 || Loss: 4.2900 || 10iter: 58.2569 sec.\n",
      "-------------\n",
      "epoch 39 || Epoch_TRAIN_Loss:50.1492 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  120.6604 sec.\n",
      "-------------\n",
      "Epoch 40/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 510 || Loss: 3.8962 || 10iter: 26.9943 sec.\n",
      ">> training iter 520 || Loss: 4.0540 || 10iter: 91.3189 sec.\n",
      "-------------\n",
      "（val）\n",
      "-------------\n",
      "epoch 40 || Epoch_TRAIN_Loss:48.7509 ||Epoch_VAL_Loss:17.5600\n",
      "timer:  134.6318 sec.\n",
      "-------------\n",
      "Epoch 41/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 530 || Loss: 3.2657 || 10iter: 95.6016 sec.\n",
      "-------------\n",
      "epoch 41 || Epoch_TRAIN_Loss:49.2126 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.6552 sec.\n",
      "-------------\n",
      "Epoch 42/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 540 || Loss: 3.4588 || 10iter: 67.1044 sec.\n",
      "-------------\n",
      "epoch 42 || Epoch_TRAIN_Loss:48.3053 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  119.1132 sec.\n",
      "-------------\n",
      "Epoch 43/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 550 || Loss: 3.5108 || 10iter: 35.0542 sec.\n",
      "-------------\n",
      "epoch 43 || Epoch_TRAIN_Loss:46.1584 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  118.2396 sec.\n",
      "-------------\n",
      "Epoch 44/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 560 || Loss: 3.3863 || 10iter: 6.9933 sec.\n",
      ">> training iter 570 || Loss: 3.6757 || 10iter: 96.0459 sec.\n",
      "-------------\n",
      "epoch 44 || Epoch_TRAIN_Loss:47.3559 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  120.6994 sec.\n",
      "-------------\n",
      "Epoch 45/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 580 || Loss: 3.7992 || 10iter: 75.1198 sec.\n",
      "-------------\n",
      "epoch 45 || Epoch_TRAIN_Loss:45.1709 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.0273 sec.\n",
      "-------------\n",
      "Epoch 46/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 590 || Loss: 3.5304 || 10iter: 46.3429 sec.\n",
      "-------------\n",
      "epoch 46 || Epoch_TRAIN_Loss:44.5484 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  121.7063 sec.\n",
      "-------------\n",
      "Epoch 47/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 600 || Loss: 3.7323 || 10iter: 17.8494 sec.\n",
      ">> training iter 610 || Loss: 3.4428 || 10iter: 97.4935 sec.\n",
      "-------------\n",
      "epoch 47 || Epoch_TRAIN_Loss:47.3633 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  123.4891 sec.\n",
      "-------------\n",
      "Epoch 48/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 620 || Loss: 3.5302 || 10iter: 85.3812 sec.\n",
      "-------------\n",
      "epoch 48 || Epoch_TRAIN_Loss:44.3350 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  122.4418 sec.\n",
      "-------------\n",
      "Epoch 49/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 630 || Loss: 3.8468 || 10iter: 58.8597 sec.\n",
      "-------------\n",
      "epoch 49 || Epoch_TRAIN_Loss:44.4717 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  125.8391 sec.\n",
      "-------------\n",
      "Epoch 50/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 640 || Loss: 3.0711 || 10iter: 28.1250 sec.\n",
      ">> training iter 650 || Loss: 3.3734 || 10iter: 92.1054 sec.\n",
      "-------------\n",
      "（val）\n",
      "-------------\n",
      "epoch 50 || Epoch_TRAIN_Loss:43.4099 ||Epoch_VAL_Loss:16.9290\n",
      "timer:  137.9492 sec.\n",
      "-------------\n",
      "Epoch 51/50\n",
      "-------------\n",
      "（train）\n",
      ">> training iter 660 || Loss: 3.2448 || 10iter: 103.2399 sec.\n",
      "-------------\n",
      "epoch 51 || Epoch_TRAIN_Loss:44.8072 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  131.4715 sec.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num_epochs= 50\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviewing initial results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxV9Z3/8dcnC0kgG5AASUCIyqKAhIor7vTnisC4IK3WZezDcWldZkShHZc6dmqrU5cZi+PUrS0/haICLYy0opRat4JEdggoShKWBElIICEL3/nj3hwSuAlJyL2H5L6fjwePe+/3nHPv54rkne/3e873mHMOERERgBi/CxARkWOHQkFERDwKBRER8SgURETEo1AQERFPnN8FHI2MjAw3aNAgv8sQEelUli9fXuqcywy1rVOHwqBBg1i2bJnfZYiIdCpm9lVz2zR8JCIiHoWCiIh4FAoiIuLp1HMKItL11NbWUlhYSHV1td+ldHqJiYn079+f+Pj4Vh+jUBCRY0phYSEpKSkMGjQIM/O7nE7LOceuXbsoLCwkNze31cdFXSjMXVHEk4s2UFxWRXZ6ElMvGcqk0Tl+lyUiQdXV1QqEDmBm9O7dm5KSkjYdF1WhMHdFEdPfWkVVbT0ARWVVTH9rFYCCQeQYokDoGO357xhVE81PLtrgBUKDqtp6nly0waeKRESOLVEVCsVlVW1qFxGJNlEVCtnpSW1qF5Fj39wVRYx94j1ypy1g7BPvMXdF0VG9X1lZGb/61a/afNzll19OWVlZm4+7+eabmTNnTpuPC5eoCoWplwwlKT62SZsBd110gj8FichRaZgnLCqrwnFwnvBogqG5UKivrw+x90ELFy4kPT293Z97rIiqieaGyeSGs48ykhMordzPR5u/4TunHafJLZFjzE/+sIa1xXua3b7i6zJq6g80aauqreeBOSt5/dOvQx5zcnYqj1w5vNn3nDZtGps3byYvL4/4+HiSk5PJysoiPz+ftWvXMmnSJLZu3Up1dTX33HMPt912G3BwLbbKykouu+wyzjnnHD788ENycnKYN28eSUlHHpFYvHgx999/P3V1dZx22mnMmDGDhIQEpk2bxvz584mLi+Piiy/mqaee4ve//z0/+clPiI2NJS0tjaVLlx7x/VsjqkIBAsHQ+Eyj/1xcwH/8eSMXDcvkH0b397EyEWmrQwPhSO2t8cQTT7B69Wry8/NZsmQJV1xxBatXr/bO9X/55Zfp1asXVVVVnHbaaVx99dX07t27yXsUFBTw+uuv8z//8z9MnjyZN998kxtuuKHFz62urubmm29m8eLFDBkyhBtvvJEZM2Zw44038vbbb7N+/XrMzBuieuyxx1i0aBE5OTntGrZqTtSFwqHuvPBE/rKxhIfnrmHMwF4M6NXd75JEJKil3+gBxj7xHkUhThTJSU9i1j+d1SE1nH766U0u/nruued4++23Adi6dSsFBQWHhUJubi55eXkAnHrqqWzZsuWIn7NhwwZyc3MZMmQIADfddBPPP/88P/jBD0hMTOT73/8+V1xxBePHjwdg7Nix3HzzzUyePJmrrrqqI74qEGVzCqHExhhPXxf4y7tvVj51R/EbhohEVqh5wqT4WKZeMrTDPqNHjx7e8yVLlvDuu+/y0Ucf8fnnnzN69OiQy3EkJCR4z2NjY6mrqzvi5zjnQrbHxcXx6aefcvXVVzN37lwuvfRSAF544QUef/xxtm7dSl5eHrt27WrrVwsp6kMBYECv7vzbpBEs+2o3v1qy2e9yRKSVJo3O4WdXjSQnPQkj0EP42VUjj+pi1JSUFCoqKkJuKy8vp2fPnnTv3p3169fz8ccft/tzDjVs2DC2bNnCpk2bAPjtb3/L+eefT2VlJeXl5Vx++eU888wz5OfnA7B582bOOOMMHnvsMTIyMti6dWuH1BH1w0cNJo3O4b31O3l2cQHnDs5g9HE9/S5JRFrh0HnCo9W7d2/Gjh3LiBEjSEpKom/fvt62Sy+9lBdeeIFTTjmFoUOHcuaZZ3bY5yYmJvLKK69w7bXXehPNt99+O9988w0TJ06kuroa5xxPP/00AFOnTqWgoADnHOPGjWPUqFEdUoc112XpDMaMGeM68s5r5VW1XP7sX4mLNRbcfS7JCcpMkUhbt24dJ510kt9ldBmh/nua2XLn3JhQ+2v4qJG0pHievi6Prd/s47E/rPG7HBGRiFMoHOL03F7cccEJzF5WyMJV2/wuR0S6iLvuuou8vLwmf1555RW/yzpM2MZHzOxlYDyw0zk3olH7D4EfAHXAAufcA8H26cCtQD1wt3NuUbhqO5J7vz2EvxaUMv2tVYw+Lp2sNC2DISJH5/nnn/e7hFYJZ0/hVeDSxg1mdiEwETjFOTcceCrYfjIwBRgePOZXZtb0PLMIio+N4dkpo6mpO8C/zP6cAwc677yLiEhbhC0UnHNLgW8Oab4DeMI5tz+4z85g+0TgDefcfufcl8Am4PRw1dYauRk9eOTKk/lw8y5+/cEXfpYiIhIxkZ5TGAKca2afmNlfzOy0YHsO0Pgk28Jg22HM7DYzW2Zmy9p6R6G2uu60AVwyvC9PLtrA6qLysH6WiMixINKhEAf0BM4EpgKzLbAKXaiV6EKO2TjnXnTOjXHOjcnMzAxfpQTuWvTEVafQq0c37p2VT1VNy6skioh0dpEOhULgLRfwKXAAyAi2D2i0X3+gOMK1hdSzRzeeunYUm3ZW8u8L1/ldjogcauVseHoEPJoeeFw5O+IlJCcnN7tty5YtjBgxotntx5pIh8Jc4CIAMxsCdANKgfnAFDNLMLNcYDDwaYRra9a5gzP5/jm5/Pbjr1i8boff5YhIg5Wz4Q93Q/lWwAUe/3C3L8HQVYTzlNTXgQuADDMrBB4BXgZeNrPVQA1wkwtcUr3GzGYDawmcqnqXc+6YGquZeulQPthUygNzVvLOveeRmZJw5INE5Oj87zTYvqr57YV/h/r9Tdtqq2DeD2D5a6GP6TcSLnuixY998MEHGThwIHfeeScAjz76KGbG0qVL2b17N7W1tTz++ONMnDixLd+G6upq7rjjDpYtW0ZcXBy//OUvufDCC1mzZg233HILNTU1HDhwgDfffJPs7GwmT55MYWEh9fX1PPTQQ1x33XVt+rz2CFsoOOe+08ymkIuKO+d+Cvw0XPUcrYS4WJ77zmiu/M8PmDrnc165+TTdlEfEb4cGwpHaW2nKlCnce++9XijMnj2bd955h/vuu4/U1FRKS0s588wzmTBhQpt+DjRcq7Bq1SrWr1/PxRdfzMaNG3nhhRe45557uP7666mpqaG+vp6FCxeSnZ3NggULgMBifJGgxX3aYEjfFH50+Uk8Mn8Nv/noK246e5DfJYl0bUf4jZ6nRwSHjg6RNgBuWdDujx09ejQ7d+6kuLiYkpISevbsSVZWFvfddx9Lly4lJiaGoqIiduzYQb9+/Vr9vh988AE//OEPgcCqqAMHDmTjxo2cddZZ/PSnP6WwsJCrrrqKwYMHM3LkSO6//34efPBBxo8fz7nnntvu79MWWuaijW48ayAXDs3k3xeuY+OO0MvrikiEjHsY4g9ZcSA+KdB+lK655hrmzJnDrFmzmDJlCjNnzqSkpITly5eTn59P3759Q95LoSXNLUD63e9+l/nz55OUlMQll1zCe++9x5AhQ1i+fDkjR45k+vTpPPbYY0f9nVpDodBGZsYvrhlFckIcd7++gv11x9TUh0h0OWUyXPlcoGeABR6vfC7QfpSmTJnCG2+8wZw5c7jmmmsoLy+nT58+xMfH8/777/PVV1+1+T3PO+88Zs6cCcDGjRv5+uuvGTp0KF988QXHH388d999NxMmTGDlypUUFxfTvXt3brjhBu6//34+++yzo/5OraHho3bITEngF9ecwq2vLePJdzbwr+NP9rskkeh1yuQOCYFDDR8+nIqKCnJycsjKyuL666/nyiuvZMyYMeTl5TFs2LA2v+edd97J7bffzsiRI4mLi+PVV18lISGBWbNm8bvf/Y74+Hj69evHww8/zN///nemTp1KTEwM8fHxzJgxo8O/Yyi6n8JReGjuan778Vf87tYzOGdwhm91iHQlup9Cx9L9FCLoR5efxAmZPfjn2fns3lvjdzkiIkdNoXAUkrrF8uyU0ezeV8O0t1Y2O4kkIl3fqlWrDrtfwhlnnOF3WW2mOYWjNCInjamXDOXfF65n9rKtXHfacX6XJNLpOec63XVAI0eOJD8/3+8ymmjPL6rqKXSA759zPGef0JtH56/ly9K9fpcj0qklJiaya9cu9byPknOOXbt2kZiY2KbjNNHcQbaVV3HpM39lUO/uzLnjbOJjlbci7VFbW0thYWGbrwGQwyUmJtK/f3/i4+ObtLc00azhow6SlZbEE1eN5I6Zn/HsuwXcf8lQv0sS6ZTi4+PJzc31u4yopV9nO9BlI7O49tT+PL9kE59+eehN50REjn0KhQ72yIThHNerO/fNyqe8qtbvckRE2kSh0MGSE+J45ro8tu+p5uF5q/0uR0SkTRQKYTD6uJ7cM24w8/KLmbuiyO9yRERaTaEQJndecAJjBvbkobmr2frNPr/LERFpFYVCmMTFxvD0dXkA3Dcrn7r6Az5XJCJyZAqFMBrQqzuPTRrOsq92M2PJZr/LERE5IoVCmE3Ky2HCqGyeWVxA/tYyv8sREWmRLl4LMzPj3yaNYPlXu7n11U/pFhfL9vJqstOTmHrJUCaNzvG7RBERT9h6Cmb2spntNLPDzss0s/vNzJlZRvC1mdlzZrbJzFaa2bfCVZcf0pLi+YfR2ezaW8u28mocUFRWxfS3VunsJBE5poRz+OhV4NJDG81sAPD/gK8bNV8GDA7+uQ2IzC2GIujtFcWHtVXV1vPkog0+VCMiElrYQsE5txQItdbD08ADQOOV+CYCv3EBHwPpZpYVrtr8UFxWFbK9qKyKimpd+Swix4aITjSb2QSgyDn3+SGbcoCtjV4XBttCvcdtZrbMzJaVlJSEqdKOl52e1Oy2MY+/y10zP2PRmu3sr6uPYFUiIk1FbKLZzLoDPwYuDrU5RFvINb2dcy8CL0Jg6ewOKzDMpl4ylOlvraKq9uAP/aT4GP7p/BPYvbeGP67cxoJV20hNjOPykVlMzMvhjNxexMR0rhuNiEjnFsmzj04AcoHPg3dU6g98ZmanE+gZDGi0b3/g8EH4TqzhLKMnF22guKzqsLOPHhp/Mh9sKmV+fjF/+LyYN/6+lX6piUzIy2bCqGyGZ6d2ujtRiUjnE9ab7JjZIOCPzrkRIbZtAcY450rN7ArgB8DlwBnAc86504/0/sfSTXY6UlVNPe+u28G8/CKWbCih7oDjhMwegWse8rIZ2LuH3yWKSCfW0k12whYKZvY6cAGQAewAHnHOvdRo+xYOhoIB/0XgbKV9wC3OuSP+tO+qodDY7r01LFy9jXkrivl0S2DefvRx6Uwclc34UdlkJCf4XKGIdDa+hEIkREMoNFZUVsX8/GLm5RexfnsFsTHG2BMzmJSXzcXD+5GcoGsRReTIFApd0IbtFczLL2JefjFFZVUkxsfw7ZP6Mikvh/OGZNItTiuYiEhoCoUu7MABx2df72ZufhELVm5j975a0rvHB85gGpXNaYN6Mf/z4mYnuEUk+igUokRt/QH+WlDCvPxi/rRmB1W19aQnxVG5v566Awf/npPiY/nZVSMVDCJRqqVQ0CB0FxIfG8NFw/py0bC+7N1fx7vrdvDAnJVNAgECy2v84p31CgUROYwGnruoHglxTMzLoaYu9M19isurufHlT/n1X7+gYEcFnbnHKCIdRz2FLi47PYmiEOsu9UiIpXD3Ph5fsI7HF6wjKy2R8wZnct6QTM45MYO07vE+VCsiflModHGhl9eI5aeTAnMKhbv3sXRjKUs3lrBw9TZmLdtKjMGoAeleSIzqn0ZcrDqVItFAE81RYO6KoladfVRXf4D8rWUs3VjCXwpKWVlYhnOQmhjHOYMzvJBoaXE/ETn26ewjaZfde2v4YFOgF7G0oIQde/YDcGKf5GBAZHDm8b1JjI/1uVIRaQuFghw15xwbd1R6AfHJl99QU3eAbnExnJHby+tFDOmb3GThvtb2UkQkchQK0uGqaur55MtdgfmIghI27awEoF9qIucOzuC8IZnsqarl8QXrDpvP0DUSIv5SKEjYFZVV8ddgL+KDglL2VNc1u29OehJ/m3ZRBKsTkcYUChJRdfUH+LywnKtnfNjsPjefPYhh/VIYlpXKkL7JdO+mE+FEIkVXNEtExcXGcOrAnuQ0c41EfKwxe9lW9tUEhpXMYGCv7gzrl8qwrBSG9UvlpKwUBvTsrjvPiUSYQkHCprlrJH521UgmjMqmcHcV67bvYf22CtZv38P67RUsWrudhs5r926xDOmbwknBoBjWL/CoC+tEwkfDRxJWbT37aF9NHQU7Klm/fQ/rGoVF2b5ab5/stESGZaUytF8Kw/qlcFJWKrkZPYhvdIGdznoSaZ7mFKRTc86xY89+r1exIRgUm3ZWeov9dYuN4cQ+yQzLSqG+3vG/q7dTU39w3Sed9SRykOYUpFMzM/qlJdIvLZELh/bx2mvqDrC5JNCrCAxBVfC3TaXeRXaNVdXWM/2tVazdtofM5AT6pCaQmZJAn5RE+qQmkJIQ1+T6CpFopVCQTqtbXAwnZaVyUlYqjD7YnjttAaH6v1W19bz64ZaQK8cmxscEAiIlEBh9UhKDodE0PHp173bEyW8NXUlnplCQLqe5lWFz0pP44MEL2VNdR0lFNTv37GdnxX52HvJ8/fYK/lpQSkWIay3iYoyM5IbgSCDzkCBZt62c59/fzP5g8BSVVTH9rVUACgbpFMIWCmb2MjAe2OmcGxFsexK4EqgBNgO3OOfKgtumA7cC9cDdzrlF4apNurbmznqaeslQzIy0pHjSkuI5sU9Ki+9TVVNPSUNoVOxn557gY/BPUVk1+VvL2LW3hpam5qpq63lk/mrSkuLJzehB/55JWnVWjllhm2g2s/OASuA3jULhYuA951ydmf0cwDn3oJmdDLwOnA5kA+8CQ5xz9aHfPUATzdKcSA7h1NYfYFdlDTsrqpnwX3874v5xMcZxvbqTm9GDQRk9yM3owfHB5/1SE3VthoSdLxPNzrmlZjbokLY/NXr5MXBN8PlE4A3n3H7gSzPbRCAgPgpXfdK1TRqdE7HhmvjYGG8ivLkL9vqlJfJf3xnNl6V7m/z52+ZSqmsPznEkxscwqHcgKBpC4/jg8149urU4Ga65DOkIfs4p/CMwK/g8h0BINCgMth3GzG4DbgM47rjjwlmfSJs1N3Q17dJhjBnUizGDejXZ/8ABx/Y91Wwp3csXpXvZEgyLDdsr+PPaHU3ur52SGOf1KHIzmgbHe+t2NvlczWVIe/kSCmb2Y6AOmNnQFGK3kONazrkXgRchMHwUlgJF2qnhB3Brf2OPiTGy05PITk/i7BMzmmyrqz9A4e6qw3oXy7bsZv7nxU3mMWIMDhzyr6Gqtp7HF6wlb0A6vZO7kazTbqUVIh4KZnYTgQnoce7ghEYhMKDRbv2B4kjXJtIROmroKi42hkHBnsCFh2yrrq3nq137vKD4+TvrQ75HaWUNFzy1BAicwpvRoxu9kxPondyNjIbHHoHH3skJZATbe/Xo1uQK8ZZo2KpriWgomNmlwIPA+c65fY02zQf+v5n9ksBE82Dg00jWJtKZJMbHMrRfCkP7Bc6g+t3HX4Wcy+jdoxs/uvwkdu3dz67KGkora7znG7dXUFpZ0+TK78bSkuK98MhI7kbvxuHRoxsZKQms+Ho3v/zzRm9eRMNWnV84T0l9HbgAyDCzQuARYDqQAPw52I392Dl3u3NujZnNBtYSGFa660hnHonIQc3NZTw0/uQWfzg756jYX8euyhp2Ve6ntLKG0spAaBwMkv1s3FFJaeWuJmtQNaeqtp4fz11FaeV++qUlkpWWSFZaEn1SEnQqbiegtY9EuohIDOPU1h9g996DPY7vvdT6Dn2MQZ+UwFla2emJ9EtNCgRGevuDQ0NX7aO1j0SiQCROw42PjaFPaiJ9UhMBmj0FNyc9kYX3nMe28iq2lVezraya7Q3Py6vZsL2CJRtKvHtqNIgxyExJICstyQuKxsHRLy2JvsHgmLuiSGdchYFCQUTarfmrx4d5V44P65ca8ljnHHuq67zg2F5ezbayg8GxcUcFf9nYfHB8s7eG2vqmIx1VtfU8uWiDQuEoKBREpN3aegpuY42XHDlScGwvr6a4vKpJcPx+eWHIY4rKqrj3jRUMz05jeE4qw7PSdGOmNtCcgoh0SmOfeC/k0FViXAzp3buxfU+119a/ZxIjstMYnp3K8JxURmSneUNg0UhzCiLS5bR0u9dJo3MordzPmuI9rCkuZ03xHtYW7+GdNdu9fTOSExiencqInNRAryI7leN6dY/6C/wUCiLSKR1p6CojOYHzh2Ry/pBM75iK6lrWbatgTXE5q4sCgfG3TaXeciIpiXGcnBUIiYawOCGzx2FnRHXls540fCQiUa26tp6NOyq8XsXqoj2s377HuyAvIS6GYf1SGJ4T6E2UVu5nxpLNTRYy7Gy3e9U9mkVE2qCu/gBflu5ldXE5a4r2sKZ4D6uLy0PeeKlB39QEPpo2rlMsfa5QEBE5Ss45CndXce4v3m92n6T4WE7sk8zgPskM7pvCkL7JDO6TQv+eScdUWGiiWUTkKJkZA3p1b/aCvfSkeK76Vn8Kdlbw4eZdvLWiyNvWWcICFAoiIm3S3FlPj04Y3mROobyqlk07KyjYUcnGHZUdFhbhnuRWKIiItEFrL9hLS4rn1IG9OHVg0xsrHU1YLN/yDT+auzqsS3toTkFE5BjQEBYbd1RSEAyLjTsq2LFnv7ePEfruYznpSfxt2kWt/izNKYiIHOOO1LPYuKPS6xUcqjjEHEd7tWqNWjO7x8xSLeAlM/vMzC7usCpERCSkhrD4zunHkZOeFHKf7Gba26O1C5f/o3NuD3AxkAncAjzRYVWIiMgRTb1kKEnxsU3aAqvSDu2wz2jt8FHDNPjlwCvOuc8t2hcIERGJsKNZlba1WhsKy83sT0AuMN3MUoDQN3YVEZGwCffNlFobCrcCecAXzrl9ZtaLwBCSiIh0Ia2dUzgL2OCcKzOzG4B/BcpbOsDMXjaznWa2ulFbLzP7s5kVBB97BtvNzJ4zs01mttLMvtXeLyQiIu3X2lCYAewzs1HAA8BXwG+OcMyrwKWHtE0DFjvnBgOLg68BLgMGB//cFvw8ERGJsNaGQp0LXOU2EXjWOfcskNLSAc65pcA3hzRPBF4LPn8NmNSo/Tcu4GMg3cyyWlmbiIh0kNaGQoWZTQe+Bywws1igPTc97euc2wYQfOwTbM8BtjbarzDYdhgzu83MlpnZspKSknaUICIizWltKFwH7CdwvcJ2Aj+wn+zAOkKd3hpy/Q3n3IvOuTHOuTGZmZmhdhERkXZqVSgEg2AmkGZm44Fq59yR5hRC2dEwLBR83BlsLwQGNNqvP1DcjvcXEZGj0NplLiYDnwLXApOBT8zsmnZ83nzgpuDzm4B5jdpvDJ6FdCZQ3jDMJCIikdPa6xR+DJzmnNsJYGaZwLvAnOYOMLPXgQuADDMrBB4hsDTGbDO7FfiaQMgALCRwtfQmYB+6BkJExBetDYWYhkAI2sURehnOue80s2lciH0dcFcraxERkTBpbSi8Y2aLgNeDr68j8Nu9iIh0Ia0KBefcVDO7GhhL4EyhF51zb4e1MhERibhW32THOfcm8GYYaxEREZ+1GApmVkHo6wWMwFRAaliqEhERX7QYCs65FpeyEBGRrqW1VzSLiEgUUCiIiIhHoSAiIh6FgoiIeBQKIiLiUSiIiIhHoSAiIh6FgoiIeBQKIiLiUSiIiIhHoSAiIh6FgoiIeBQKIiLiUSiIiIhHoSAiIh5fQsHM7jOzNWa22sxeN7NEM8s1s0/MrMDMZplZNz9qExGJZhEPBTPLAe4GxjjnRgCxwBTg58DTzrnBwG7g1kjXJiIS7fwaPooDkswsDugObAMuAuYEt78GTPKpNhGRqBXxUHDOFQFPAV8TCINyYDlQ5pyrC+5WCOSEOt7MbjOzZWa2rKSkJBIli4hEDT+Gj3oCE4FcIBvoAVwWYlcX6njn3IvOuTHOuTGZmZnhK1REJAr5MXz0beBL51yJc64WeAs4G0gPDicB9AeKfahNRCSq+REKXwNnmll3MzNgHLAWeB+4JrjPTcA8H2oTEYlqfswpfEJgQvkzYFWwhheBB4F/NrNNQG/gpUjXJiIS7eKOvEvHc849AjxySPMXwOk+lCMiIkG6ollERDwKBRER8SgURETEo1AQERGPQkFERDwKBRER8SgURETEo1AQERGPQkFERDwKBRER8SgURETEo1AQERGPQkFERDwKBRER8SgURETEo1AQERGPQkFERDwKBRER8SgURETEo1AQERGPL6FgZulmNsfM1pvZOjM7y8x6mdmfzawg+NjTj9pERKKZXz2FZ4F3nHPDgFHAOmAasNg5NxhYHHwtIiIRFPFQMLNU4DzgJQDnXI1zrgyYCLwW3O01YFKkaxMRiXZ+9BSOB0qAV8xshZn92sx6AH2dc9sAgo99Qh1sZreZ2TIzW1ZSUhK5qkVEooAfoRAHfAuY4ZwbDeylDUNFzrkXnXNjnHNjMjMzw1WjiEhU8iMUCoFC59wnwddzCITEDjPLAgg+7vShNhGRqBbxUHDObQe2mtnQYNM4YC0wH7gp2HYTMC/StYmIRLs4nz73h8BMM+sGfAHcQiCgZpvZrcDXwLU+1SYiErV8CQXnXD4wJsSmcZGuRUREDtIVzSIi4lEoiIiIR6EgIiIehYKIiHgUCiIi4lEoiIiIR6EgIiIehYKIiHgUCiIi4lEoiIiIR6EgIiIehYKIiHgUCiIi4lEoiIiIR6EgIiIehYKIiHgUCiIi4lEoiIiIR6EgIiIehYKIiHh8CwUzizWzFWb2x+DrXDP7xMwKzGyWmXXzqzYRkWjlZ0/hHmBdo9c/B552zg0GdgO3+lKViEgU8yUUzKw/cAXw6+BrAy4C5gR3eQ2Y5EdtIiLRzK+ewkgbNsUAAAYISURBVDPAA8CB4OveQJlzri74uhDICXWgmd1mZsvMbFlJSUn4KxURiSIRDwUzGw/sdM4tb9wcYlcX6njn3IvOuTHOuTGZmZlhqVFEJFrF+fCZY4EJZnY5kAikEug5pJtZXLC30B8o9qE2EZGoFvGegnNuunOuv3NuEDAFeM85dz3wPnBNcLebgHmRrk1EJNodS9cpPAj8s5ltIjDH8JLP9YiIRB0/ho88zrklwJLg8y+A0/2sR0Qk2h1LPQUREfGZQkFEpK1WzoanR8Cj6YHHlbP9rqjD+Dp8JCLS6aycDX+4G2qrAq/LtwZeA5wy2b+6Ooh6CiIibbH4sYOB0KC2KtDeBSgURETaorywbe2djEJBRKQt0vq3rb2TUSiIiLTFuIchPqlpW3xSoL0LUCiIiLTFKZPhyucgbQBggccrn+sSk8ygs49ERNrulMldJgQOpZ6CiIh4FAoiIuJRKIiIiEehICIiHoWCiIh4zLmQd73sFMysBPjK7zraIQMo9buICNN37vqi7ftC5/3OA51zIe9n3KlDobMys2XOuTF+1xFJ+s5dX7R9X+ia31nDRyIi4lEoiIiIR6Hgjxf9LsAH+s5dX7R9X+iC31lzCiIi4lFPQUREPAoFERHxKBQixMwGmNn7ZrbOzNaY2T1+1xQpZhZrZivM7I9+1xIJZpZuZnPMbH3w7/ssv2sKNzO7L/j/9Woze93MEv2uqaOZ2ctmttPMVjdq62VmfzazguBjTz9r7AgKhcipA/7FOXcScCZwl5md7HNNkXIPsM7vIiLoWeAd59wwYBRd/LubWQ5wNzDGOTcCiAWm+FtVWLwKXHpI2zRgsXNuMLA4+LpTUyhEiHNum3Pus+DzCgI/KHL8rSr8zKw/cAXwa79riQQzSwXOA14CcM7VOOfK/K0qIuKAJDOLA7oDxT7X0+Gcc0uBbw5pngi8Fnz+GjApokWFgULBB2Y2CBgNfOJvJRHxDPAAcMDvQiLkeKAEeCU4ZPZrM+vhd1Hh5JwrAp4Cvga2AeXOuT/5W1XE9HXObYPAL35AH5/rOWoKhQgzs2TgTeBe59wev+sJJzMbD+x0zi33u5YIigO+Bcxwzo0G9tIFhhRaEhxHnwjkAtlADzO7wd+qpL0UChFkZvEEAmGmc+4tv+uJgLHABDPbArwBXGRmv/O3pLArBAqdcw29wDkEQqIr+zbwpXOuxDlXC7wFnO1zTZGyw8yyAIKPO32u56gpFCLEzIzAOPM659wv/a4nEpxz051z/Z1zgwhMPL7nnOvSv0E657YDW81saLBpHLDWx5Ii4WvgTDPrHvz/fBxdfHK9kfnATcHnNwHzfKylQ8T5XUAUGQt8D1hlZvnBth855xb6WJOExw+BmWbWDfgCuMXnesLKOfeJmc0BPiNwlt0KuuLyD2avAxcAGWZWCDwCPAHMNrNbCYTjtf5V2DG0zIWIiHg0fCQiIh6FgoiIeBQKIiLiUSiIiIhHoSAiIh6FgohPzOyCaFk5VjoPhYKIiHgUCiJHYGY3mNmnZpZvZv8dvD9EpZn9h5l9ZmaLzSwzuG+emX1sZivN7O2G9fXN7EQze9fMPg8ec0Lw7ZMb3XthZvCKYBHfKBREWmBmJwHXAWOdc3lAPXA90AP4zDn3LeAvBK5uBfgN8KBz7hRgVaP2mcDzzrlRBNYF2hZsHw3cC5xMYIXVsWH/UiIt0DIXIi0bB5wK/D34S3wSgUXPDgCzgvv8DnjLzNKAdOfcX4LtrwG/N7MUIMc59zaAc64aIPh+nzrnCoOv84FBwAfh/1oioSkURFpmwGvOuelNGs0eOmS/ltaLaWlIaH+j5/Xo36T4TMNHIi1bDFxjZn3AuyfvQAL/dq4J7vNd4APnXDmw28zODbZ/D/hL8L4ZhWY2KfgeCWbWPaLfQqSV9FuJSAucc2vN7F+BP5lZDFAL3EXg5jnDzWw5UE5g3gECyye/EPyh33iF1O8B/21mjwXfo9Ovpildk1ZJFWkHM6t0ziX7XYdIR9PwkYiIeNRTEBERj3oKIiLiUSiIiIhHoSAiIh6FgoiIeBQKIiLi+T/1UTN34Q0HKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../outputs/log_output_dev_053120.csv\",encoding = 'UTF8')\n",
    "\n",
    "plt.plot(data['epoch'],data['train_loss'], marker='o', label='train_loss')\n",
    "plt.plot(data['epoch'][9:50:10],data['val_loss'][9:50:10], marker='o',label=\"val_loss\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../outputs/log_output_dev_053120.csv\",encoding = 'UTF8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.494267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140.631291</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>133.139671</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>127.261935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>123.464974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  epoch  train_loss  val_loss\n",
       "0           0      1  170.494267       0.0\n",
       "1           1      2  140.631291       0.0\n",
       "2           2      3  133.139671       0.0\n",
       "3           3      4  127.261935       0.0\n",
       "4           4      5  123.464974       0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
